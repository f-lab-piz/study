# AI/ML 핵심 개념 - 프론트엔드 개발자를 위한 가이드

프론트엔드 개발자로서 AI 프로젝트에 참여할 때, 직접 모델을 개발하지는 않더라도 팀과 효과적으로 소통하기 위해 기본 개념을 이해하는 것이 중요합니다.

## 1. AI, 머신러닝, 딥러닝의 차이

```
AI (인공지능)
└── Machine Learning (머신러닝)
    └── Deep Learning (딥러닝)
```

### AI (Artificial Intelligence)
인간의 지능을 모방하는 모든 기술을 의미합니다.

**예시**:
- 규칙 기반 챗봇 (if-else로 작성된 것도 AI)
- 체스 프로그램
- 음성 인식
- 이미지 분류

### 머신러닝 (Machine Learning)
데이터로부터 패턴을 학습하여 예측하는 기술입니다.

**프론트엔드 비유**:
```javascript
// 전통적 프로그래밍
function isSpam(email) {
    if (email.includes('광고') || email.includes('무료')) {
        return true;
    }
    return false;
}

// 머신러닝 접근
// 수천 개의 스팸/정상 메일 데이터로 학습
// 모델이 스스로 패턴을 찾아냄
const isSpam = model.predict(email);
```

### 딥러닝 (Deep Learning)
신경망(Neural Network)을 여러 층 쌓아서 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다.

**특징**:
- 대량의 데이터 필요
- 높은 컴퓨팅 파워 필요
- 이미지, 음성, 텍스트 처리에 강력

## 2. 머신러닝의 3가지 학습 방법

### 지도 학습 (Supervised Learning)
정답이 있는 데이터로 학습합니다.

**예시**:
```python
# 데이터: 집 크기 → 가격 (정답 레이블이 있음)
training_data = [
    {"size": 30, "price": 300},  # 30평 → 3억
    {"size": 40, "price": 400},  # 40평 → 4억
    {"size": 50, "price": 500},  # 50평 → 5억
]

# 모델 학습 후 예측
# model.predict(size=35) → 약 350 (3.5억)
```

**프론트엔드 사용 사례**:
- 스팸 메일 필터링 (스팸/정상 분류)
- 감정 분석 (긍정/부정/중립)
- 이미지 분류 (고양이/강아지)

### 비지도 학습 (Unsupervised Learning)
정답 없이 데이터의 패턴을 찾습니다.

**예시**:
```python
# 사용자들을 비슷한 그룹으로 묶기 (클러스터링)
users = [
    {"age": 25, "purchase": 10},
    {"age": 26, "purchase": 12},
    {"age": 60, "purchase": 5},
    {"age": 62, "purchase": 6},
]

# 모델이 자동으로 "젊은 활발한 구매층", "나이든 적게 구매층"으로 구분
```

**프론트엔드 사용 사례**:
- 사용자 세그먼테이션
- 추천 시스템 (비슷한 상품 찾기)
- 이상 탐지 (비정상 로그인 패턴)

### 강화 학습 (Reinforcement Learning)
보상을 통해 최적의 행동을 학습합니다.

**비유**: 게임에서 높은 점수를 받기 위해 시행착오를 거치며 전략을 배우는 것

**사용 사례**: 게임 AI, 로봇 제어, 자율주행

## 3. 학습(Training) vs 추론(Inference)

이 개념은 프론트엔드와 백엔드 개발의 차이와 비슷합니다.

### 학습 (Training) = 빌드 타임

모델을 만드는 과정입니다.

```python
# 학습 단계 (ML 엔지니어가 하는 작업)
from sklearn.linear_model import LogisticRegression

# 1. 데이터 준비
X_train = [[1, 2], [2, 3], [3, 4]]  # 특성(features)
y_train = [0, 0, 1]  # 레이블(labels)

# 2. 모델 생성 및 학습
model = LogisticRegression()
model.fit(X_train, y_train)  # 학습! (시간 오래 걸림)

# 3. 모델 저장
import joblib
joblib.dump(model, 'model.pkl')
```

**특징**:
- 시간이 오래 걸림 (몇 시간 ~ 몇 주)
- 강력한 GPU/TPU 필요
- 대량의 데이터 사용
- 주로 ML 엔지니어가 담당

### 추론 (Inference) = 런타임

학습된 모델을 실제로 사용하는 과정입니다.

```python
# 추론 단계 (프론트엔드가 호출하는 API)
import joblib

# 1. 저장된 모델 로드
model = joblib.load('model.pkl')

# 2. 예측 (빠름!)
result = model.predict([[2.5, 3.5]])
print(result)  # [0] 또는 [1]
```

**특징**:
- 빠름 (밀리초 ~ 초)
- 상대적으로 적은 리소스
- 프론트엔드가 API로 호출하는 부분

**프론트엔드 비유**:
```javascript
// 학습 = Webpack 빌드 (오래 걸림)
npm run build  // 몇 분 소요

// 추론 = 빌드된 앱 실행 (빠름)
// 사용자가 버튼 클릭 → 즉시 반응
```

## 4. 협업시 필수 용어

### 모델 (Model)
학습된 AI의 "뇌"입니다. 파일로 저장되어 배포됩니다.

```python
# 모델 파일 예시
# model.pkl, model.h5, model.pth, model.onnx
```

**프론트엔드 비유**: 빌드된 JavaScript 번들 파일

### 데이터셋 (Dataset)
모델 학습에 사용되는 데이터 모음입니다.

```python
# 이미지 분류 데이터셋 예시
dataset = {
    "train": [
        {"image": "cat1.jpg", "label": "cat"},
        {"image": "dog1.jpg", "label": "dog"},
        # ... 수천~수백만 개
    ],
    "test": [
        {"image": "cat_test.jpg", "label": "cat"},
        # ...
    ]
}
```

**용어**:
- **Training set**: 학습용 데이터 (80%)
- **Validation set**: 검증용 데이터 (10%)
- **Test set**: 최종 평가용 데이터 (10%)

### 특성 / 피처 (Feature)
모델이 학습하는 입력 데이터의 속성입니다.

```python
# 집 가격 예측 모델의 특성
house_features = {
    "size": 35,        # 평수
    "rooms": 3,        # 방 개수
    "age": 5,          # 건물 연식
    "location": "강남"  # 위치
}
```

**프론트엔드 비유**: API 요청의 파라미터

### 레이블 (Label)
지도 학습에서 정답 데이터입니다.

```python
# 이메일 스팸 분류
{
    "email": "무료 혜택 받으세요!",
    "label": "spam"  # 이게 레이블 (정답)
}
```

### 파인튜닝 (Fine-tuning)
기존에 학습된 모델을 특정 작업에 맞게 재학습하는 것입니다.

**비유**:
```javascript
// 기본 React 컴포넌트 (사전 학습된 모델)
import { Button } from 'library';

// 우리 프로젝트에 맞게 커스터마이징 (파인튜닝)
const CustomButton = styled(Button)`
  color: blue;
  /* 우리 디자인에 맞게 조정 */
`;
```

**예시**:
- GPT-3.5를 우리 회사 고객센터 데이터로 파인튜닝
- 이미지 인식 모델을 우리 제품 이미지로 파인튜닝

### 임베딩 (Embedding)
텍스트나 이미지를 숫자 벡터로 변환한 것입니다.

```python
# 텍스트 → 숫자 벡터
"고양이" → [0.2, 0.8, 0.1, ..., 0.5]  # 수백~수천 차원
"강아지" → [0.3, 0.7, 0.2, ..., 0.4]

# 비슷한 단어는 비슷한 벡터를 가짐
```

**왜 필요한가?**
- 컴퓨터는 숫자만 이해할 수 있음
- 의미상 유사도 계산 가능
- 검색, 추천 시스템에 활용

**프론트엔드에서 사용**:
```python
# 사용자 검색어와 비슷한 상품 찾기
search_query = "편안한 운동화"
query_embedding = model.encode(search_query)

# 모든 상품과 유사도 계산
for product in products:
    similarity = cosine_similarity(query_embedding, product.embedding)
    # 유사도 높은 순으로 정렬
```

### 토큰 (Token)
텍스트를 처리하는 기본 단위입니다.

```python
# 한글 토큰화 예시
text = "안녕하세요 반갑습니다"

# 방법 1: 공백 기준
tokens = ["안녕하세요", "반갑습니다"]  # 2 토큰

# 방법 2: 형태소 기준
tokens = ["안녕", "하", "세요", "반갑", "습니다"]  # 5 토큰

# GPT 같은 모델
tokens = ["안녕", "하세요", " 반", "갑습니다"]  # 약 4 토큰 (모델마다 다름)
```

**왜 중요한가?**
- OpenAI API는 토큰 수로 요금 부과
- 토큰 제한이 있음 (GPT-3.5: 4K, GPT-4: 8K~32K)
- 프론트엔드에서 입력 길이 제한 필요

```python
# OpenAI 사용 예시
import tiktoken

encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
text = "프론트엔드 개발자를 위한 AI 가이드"
tokens = encoding.encode(text)
print(f"토큰 수: {len(tokens)}")  # 약 15-20 토큰
```

### 프롬프트 (Prompt)
LLM에게 주는 지시문입니다.

```python
# 나쁜 프롬프트
prompt = "번역해줘"

# 좋은 프롬프트
prompt = """
당신은 전문 번역가입니다.
다음 영어 문장을 자연스러운 한국어로 번역해주세요.
격식있는 문체를 사용하세요.

영어: "Hello, how are you?"
한국어:
"""
```

## 5. 성능 지표 (ML 팀과 소통할 때)

### 정확도 (Accuracy)
전체 중 맞춘 비율입니다.

```python
# 100개 예측 중 90개 맞춤
accuracy = 90 / 100 = 0.9 (90%)
```

**주의**: 데이터가 불균형하면 의미 없음
```python
# 예시: 스팸 메일 필터
# 정상 메일 95개, 스팸 5개
# 모델이 모든 메일을 "정상"으로 예측
# → 정확도 95%지만 스팸을 하나도 못 잡음!
```

### 정밀도 (Precision) vs 재현율 (Recall)

```python
# 스팸 필터 예시
총 100개 메일:
- 실제 스팸: 10개
- 실제 정상: 90개

모델 예측 결과:
- 스팸으로 예측: 8개 → 그 중 6개가 진짜 스팸
- 정상으로 예측: 92개

정밀도 = 6 / 8 = 75%  # "스팸이라 예측한 것 중 진짜 스팸 비율"
재현율 = 6 / 10 = 60%  # "진짜 스팸 중 찾아낸 비율"
```

**프론트엔드에서 어떻게 활용?**
- **정밀도 중요**: 추천 시스템 (잘못된 추천 줄이기)
- **재현율 중요**: 검색 기능 (관련된 결과 최대한 많이)

### 과적합 (Overfitting) vs 과소적합 (Underfitting)

```python
# 과적합: 학습 데이터만 너무 잘 맞춤
training_accuracy = 99%  # 학습 데이터에서는 완벽
test_accuracy = 60%      # 새 데이터에서는 형편없음

# 과소적합: 너무 단순해서 패턴을 못 찾음
training_accuracy = 65%  # 학습 데이터도 못 맞춤
test_accuracy = 63%      # 새 데이터도 못 맞춤

# 이상적
training_accuracy = 85%
test_accuracy = 83%      # 비슷한 성능
```

**프론트엔드 비유**:
```javascript
// 과적합: 특정 브라우저에서만 동작
if (browser === 'Chrome 98.0.4758.102') {
    // 너무 구체적!
}

// 적절한 일반화
if (browser.startsWith('Chrome')) {
    // 다양한 Chrome 버전에서 동작
}
```

## 6. ML 엔지니어/데이터 과학자와 대화하기

### 좋은 질문 예시

```
❌ "모델 정확도 올릴 수 있어요?"
✅ "현재 사용자 피드백 보니 추천 상품이 잘 안 맞는 것 같아요.
   클릭률이 5%인데, 10%로 올릴 수 있을까요?"

❌ "AI 붙이면 되죠?"
✅ "사용자가 업로드한 이미지에서 텍스트를 추출하고 싶은데,
   어떤 모델을 사용하면 좋을까요? 평균 응답 시간은 어느 정도일까요?"

❌ "왜 이렇게 느려요?"
✅ "현재 API 응답이 3초 걸리는데, 사용자 경험상 1초 이내가 필요해요.
   모델 경량화나 캐싱으로 개선 가능할까요?"
```

### 요구사항 전달시 포함할 내용

```python
# 프론트엔드 개발자가 작성하면 좋은 요구사항
requirements = {
    "기능": "상품 이미지로 비슷한 상품 찾기",
    "입력": "JPG/PNG 이미지, 최대 5MB",
    "출력": "유사 상품 5개 리스트 (ID, 유사도 점수)",
    "성능": "응답 시간 1초 이내",
    "트래픽": "1일 10만 요청 예상",
    "정확도": "상위 5개 중 최소 3개는 관련 상품이어야 함",
    "에러 처리": "이미지 인식 실패시 대체 추천 로직 필요",
}
```

## 7. 실전 예시: 챗봇 프로젝트 대화

```
프론트엔드: "챗봇이 사용자 질문에 답변을 생성하는데,
           가끔 이상한 답변을 해요. 어떻게 개선할 수 있을까요?"

ML 엔지니어: "프롬프트 엔지니어링을 개선하거나,
            RAG(Retrieval-Augmented Generation)를 도입해서
            우리 DB 데이터를 참고하게 할 수 있어요."

프론트엔드: "RAG가 뭔가요?"

ML 엔지니어: "모델이 답변하기 전에 관련 문서를 먼저 검색해서
            그걸 참고해서 답변하는 방식이에요.
            임베딩으로 유사도 검색하고, 그 결과를 프롬프트에 포함시켜요."

프론트엔드: "그럼 응답 시간이 더 걸리겠네요?
           현재 2초인데 얼마나 늘어날까요?"

ML 엔지니어: "벡터 DB를 잘 최적화하면 0.5초 정도 추가될 것 같아요.
            총 2.5초 정도요."

프론트엔드: "UX상 3초 이상은 어려울 것 같아요.
           자주 묻는 질문은 캐싱하면 어떨까요?"

ML 엔지니어: "좋은 생각이에요! Redis로 캐싱 레이어 추가하죠."
```

## 요약

### 꼭 알아야 할 핵심
1. **AI ⊃ ML ⊃ DL**: 딥러닝은 머신러닝의 일부
2. **학습 vs 추론**: 학습은 오래 걸림, 추론은 빠름
3. **토큰**: LLM API 비용과 직결
4. **임베딩**: 텍스트/이미지를 벡터로 변환, 유사도 계산에 사용
5. **파인튜닝**: 기존 모델을 우리 데이터로 재학습

### 협업 팁
- 구체적인 요구사항 제시 (응답 시간, 정확도, 트래픽)
- 사용자 경험 관점에서 피드백
- 캐싱, 배치 처리 등 최적화 아이디어 제안
- 에러 처리와 폴백 전략 고민

ML 엔지니어는 모델을, 프론트엔드 개발자는 UX를 책임집니다. 서로의 영역을 이해하고 협력하면 훌륭한 AI 제품을 만들 수 있습니다!
