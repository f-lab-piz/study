{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. LangChain 기초 실습\n",
    "\n",
    "## 학습 목표\n",
    "- LangChain으로 LLM을 추상화하여 사용하기\n",
    "- Prompt Template, Output Parser, Chain 사용하기\n",
    "- 메모리를 활용한 멀티턴 챗봇 만들기\n",
    "- 스트리밍 응답 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom dotenv import load_dotenv, find_dotenv\n\n# find_dotenv(): 현재 디렉토리부터 상위로 올라가며 .env 파일을 자동으로 찾음\n# 프로젝트 루트(/workspaces/study/.env)에 .env 파일을 두면 어디서든 동작\nload_dotenv(find_dotenv())\n\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n\nif not OPENAI_API_KEY:\n    print(\"⚠️ 프로젝트 루트에 .env 파일을 생성하고 OPENAI_API_KEY를 설정하세요\")\nelse:\n    print(\"✅ API 키 로드 완료\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM 추상화 클래스\n",
    "\n",
    "LangChain은 다양한 LLM API를 통일된 인터페이스로 사용할 수 있게 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 간단한 호출\n",
    "response = llm.invoke(\"Python의 장점 3가지를 알려줘\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 LLM 제공자\n",
    "\n",
    "같은 인터페이스로 다른 LLM도 사용 가능:\n",
    "\n",
    "```python\n",
    "# OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Anthropic Claude\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "\n",
    "# 사용법은 동일!\n",
    "response = llm.invoke(\"Hello\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Template\n",
    "\n",
    "프롬프트를 재사용 가능하게 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 정의\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{text}를 {language}로 번역해줘\"\n",
    ")\n",
    "\n",
    "# 템플릿 포맷팅\n",
    "formatted = prompt.format(text=\"Hello World\", language=\"한국어\")\n",
    "print(formatted)\n",
    "print()\n",
    "\n",
    "# LLM에 전달\n",
    "response = llm.invoke(formatted)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate (시스템 + 사용자 메시지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 친절한 {role} 선생님이야.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "messages = prompt.format_messages(\n",
    "    role=\"Python\",\n",
    "    question=\"데코레이터가 뭐야?\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output Parser\n",
    "\n",
    "LLM의 문자열 출력을 구조화된 데이터로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# LLM 응답을 문자열로 파싱\n",
    "response = llm.invoke(\"Hi there!\")\n",
    "parsed = parser.parse(response)\n",
    "print(type(parsed))  # <class 'str'>\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Output Parser (구조화된 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 출력 스키마 정의\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"사람의 이름\")\n",
    "    age: int = Field(description=\"사람의 나이\")\n",
    "    occupation: str = Field(description=\"직업\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "# 프롬프트에 포맷 지시 포함\n",
    "prompt = PromptTemplate(\n",
    "    template=\"다음 인물의 정보를 추출해줘:\\n{format_instructions}\\n\\n{query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({\"query\": \"철수는 30살이고 개발자로 일하고 있다.\"})\n",
    "\n",
    "print(f\"이름: {result.name}\")\n",
    "print(f\"나이: {result.age}\")\n",
    "print(f\"직업: {result.occupation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain (체인)\n",
    "\n",
    "LCEL(LangChain Expression Language)로 컴포넌트를 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 컴포넌트 정의\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대해 한 문장으로 설명해줘\")\n",
    "llm = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 체인 구성 (파이프 연산자)\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 실행\n",
    "result = chain.invoke({\"topic\": \"LangChain\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순차 체인 (Sequential Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 아이디어 생성\n",
    "idea_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{industry} 분야의 스타트업 아이디어를 하나 제시해줘\"\n",
    ")\n",
    "idea_chain = idea_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 2단계: 아이디어 분석\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 아이디어를 분석해줘:\\n{idea}\\n\\n장단점을 알려줘.\"\n",
    ")\n",
    "analysis_chain = analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 전체 체인 조합\n",
    "full_chain = (\n",
    "    {\"idea\": idea_chain}\n",
    "    | analysis_chain\n",
    ")\n",
    "\n",
    "result = full_chain.invoke({\"industry\": \"헬스케어\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 메모리 (Memory)\n",
    "\n",
    "LLM이 이전 대화를 기억하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 대화 저장\n",
    "memory.save_context(\n",
    "    {\"input\": \"내 이름은 철수야\"},\n",
    "    {\"output\": \"안녕하세요 철수님!\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"내 이름이 뭐였지?\"},\n",
    "    {\"output\": \"철수님이라고 하셨어요.\"}\n",
    ")\n",
    "\n",
    "# 메모리 확인\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationChain (대화 체인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False  # True로 하면 내부 동작 확인 가능\n",
    ")\n",
    "\n",
    "# 대화\n",
    "print(\"Bot:\", conversation.predict(input=\"내 이름은 영희야\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"내 이름이 뭐였지?\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"방금 뭘 물어봤어?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 멀티턴 챗봇\n",
    "\n",
    "완전한 대화형 챗봇을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 설정\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False)\n",
    "\n",
    "# 테스트 대화\n",
    "test_messages = [\n",
    "    \"안녕! 나는 Python 배우는 중이야\",\n",
    "    \"데코레이터가 뭔지 알려줄래?\",\n",
    "    \"예제 코드도 보여줘\",\n",
    "    \"내가 뭘 배우고 있다고 했지?\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"You: {msg}\")\n",
    "    response = conversation.predict(input=msg)\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Memory (최근 K개만 기억)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 최근 2개 대화만 유지\n",
    "window_memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "conversation.predict(input=\"메시지 1\")\n",
    "conversation.predict(input=\"메시지 2\")\n",
    "conversation.predict(input=\"메시지 3\")  # 메시지 1은 잊혀짐\n",
    "print(window_memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 스트리밍\n",
    "\n",
    "응답을 실시간으로 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대한 짧은 이야기를 써줘\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 스트리밍\n",
    "for chunk in chain.stream({\"topic\": \"로봇\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 실습 과제\n",
    "\n",
    "### Level 1\n",
    "1. PromptTemplate으로 다국어 번역기 만들기 (한국어→영어, 영어→일본어 등)\n",
    "2. PydanticOutputParser로 영화 정보(제목, 감독, 장르, 개봉년도) 추출하기\n",
    "3. ConversationChain으로 간단한 챗봇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 1: 다국어 번역기\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2\n",
    "4. 순차 체인으로 \"키워드 생성 → 블로그 제목 생성 → 본문 작성\" 파이프라인\n",
    "5. ConversationBufferWindowMemory로 최근 3개 대화만 기억하는 챗봇\n",
    "6. 스트리밍으로 긴 답변을 실시간으로 출력하는 Q&A 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 2: 블로그 작성 파이프라인\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 3\n",
    "7. Few-shot 프롬프트로 감성 분석기 만들기\n",
    "8. 세션별로 대화를 관리하는 멀티 유저 챗봇\n",
    "9. 병렬 체인으로 같은 질문을 여러 모델에 동시에 보내고 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 3: Few-shot 감성 분석\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "LangChain의 장점:\n",
    "- ✅ 통일된 인터페이스로 다양한 LLM 사용\n",
    "- ✅ 프롬프트를 템플릿으로 재사용\n",
    "- ✅ 출력을 구조화된 데이터로 파싱\n",
    "- ✅ 체인으로 복잡한 워크플로우 구성\n",
    "- ✅ 메모리로 대화 컨텍스트 유지\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "이제 Langfuse로 LangChain 애플리케이션을 모니터링해봅시다!\n",
    "\n",
    "👉 [07_langfuse_practice.ipynb](07_langfuse_practice.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}