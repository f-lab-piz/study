{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LLM API ê¸°ì´ˆ ì‹¤ìŠµ\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- curlê³¼ Python requestsë¡œ LLM API ì§ì ‘ í˜¸ì¶œí•˜ê¸°\n",
    "- API íŒŒë¼ë¯¸í„°(temperature, max_tokens ë“±) ì´í•´í•˜ê¸°\n",
    "- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"âš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”\")\n",
    "else:\n",
    "    print(\"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ê¸°ë³¸ API í˜¸ì¶œ\n",
    "\n",
    "### curl ëª…ë ¹ì–´ (í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰)\n",
    "```bash\n",
    "curl https://api.openai.com/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "  -d '{\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "  }'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python requestsë¡œ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(prompt: str) -> str:\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = call_openai(\"Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ëŠ”?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API íŒŒë¼ë¯¸í„° ì‹¤í—˜\n",
    "\n",
    "### ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
    "- **model**: ì‚¬ìš©í•  ëª¨ë¸ (gpt-3.5-turbo, gpt-4 ë“±)\n",
    "- **temperature**: ì°½ì˜ì„± ì¡°ì ˆ (0.0=ê²°ì •ë¡ ì , 2.0=ë§¤ìš° ì°½ì˜ì )\n",
    "- **max_tokens**: ìµœëŒ€ ìƒì„± í† í° ìˆ˜\n",
    "- **messages**: ëŒ€í™” íˆìŠ¤í† ë¦¬ (system, user, assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_advanced(prompt, temperature=0.7, max_tokens=150):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    result = response.json()\n",
    "    \n",
    "    return {\n",
    "        \"content\": result[\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"usage\": result[\"usage\"]\n",
    "    }\n",
    "\n",
    "# Temperature ë¹„êµ\n",
    "prompt = \"AIì— ëŒ€í•œ í•œ ë¬¸ì¥ ì„¤ëª…ì„ ì¨ì¤˜\"\n",
    "\n",
    "print(\"Temperature = 0.2 (ì¼ê´€ì )\")\n",
    "print(call_openai_advanced(prompt, temperature=0.2)[\"content\"])\n",
    "\n",
    "print(\"\\nTemperature = 1.5 (ì°½ì˜ì )\")\n",
    "print(call_openai_advanced(prompt, temperature=1.5)[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ë©€í‹°í„´ ëŒ€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_multiturn(messages):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    data = {\"model\": \"gpt-3.5-turbo\", \"messages\": messages}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ëŒ€í™” ì‹œì‘\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì¹œì ˆí•œ Python ì„ ìƒë‹˜ì´ì•¼.\"},\n",
    "    {\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼\"}\n",
    "]\n",
    "\n",
    "response1 = chat_multiturn(conversation)\n",
    "print(f\"Bot: {response1}\\n\")\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response1})\n",
    "\n",
    "# ì´ì „ ëŒ€í™” ê¸°ì–µ\n",
    "conversation.append({\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"})\n",
    "response2 = chat_multiturn(conversation)\n",
    "print(f\"Bot: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
    "\n",
    "ê¸´ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_streaming(prompt):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line = line.decode('utf-8')\n",
    "            if line.startswith(\"data: \") and line.strip() != \"data: [DONE]\":\n",
    "                try:\n",
    "                    data = json.loads(line[6:])\n",
    "                    delta = data[\"choices\"][0].get(\"delta\", {})\n",
    "                    if \"content\" in delta:\n",
    "                        print(delta[\"content\"], end=\"\", flush=True)\n",
    "                except:\n",
    "                    pass\n",
    "    print()  # ì¤„ë°”ê¿ˆ\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "call_openai_streaming(\"Pythonì˜ ì¥ì  3ê°€ì§€ë¥¼ ì„¤ëª…í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹¤ìŠµ ê³¼ì œ\n",
    "\n",
    "### Level 1\n",
    "1. temperatureë¥¼ 0.0, 0.5, 1.0, 1.5ë¡œ ë°”ê¿”ê°€ë©° \"ë¡œë´‡ì— ëŒ€í•œ ì´ì•¼ê¸°\"ë¥¼ 3ë²ˆì”© ìƒì„±í•´ë³´ê³  ì°¨ì´ì  ê´€ì°°\n",
    "2. max_tokensë¥¼ 20, 50, 100ìœ¼ë¡œ ì„¤ì •í•˜ê³  ì‘ë‹µ ê¸¸ì´ ë¹„êµ\n",
    "3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì–‘í•˜ê²Œ ë°”ê¿”ë³´ê¸° (í•´ì , ì…°ìµìŠ¤í”¼ì–´, ê³¼í•™ì ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì œ 1: Temperature ì‹¤í—˜\n",
    "# TODO: ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2\n",
    "4. í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚° í•¨ìˆ˜ ë§Œë“¤ê¸° (GPT-3.5: input $0.0015/1K, output $0.002/1K)\n",
    "5. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì œ 2: ë¹„ìš© ê³„ì‚°\n",
    "def calculate_cost(prompt_tokens, completion_tokens):\n",
    "    # TODO: êµ¬í˜„\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì œ LangChainìœ¼ë¡œ ì´ëŸ° ì‘ì—…ë“¤ì„ ë” ì‰½ê²Œ í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "ğŸ‘‰ [06_langchain_practice.ipynb](06_langchain_practice.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
