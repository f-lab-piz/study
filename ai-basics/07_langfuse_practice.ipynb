{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Langfuse ê¸°ì´ˆ ì‹¤ìŠµ\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Dockerë¡œ Langfuseë¥¼ ì…€í”„ í˜¸ìŠ¤íŒ…í•˜ê¸°\n",
    "- Trace loggingìœ¼ë¡œ LLM í˜¸ì¶œ ì¶”ì í•˜ê¸°\n",
    "- LangChainê³¼ í†µí•©í•˜ì—¬ ìë™ìœ¼ë¡œ ë¡œê¹…í•˜ê¸°\n",
    "- ëŒ€ì‹œë³´ë“œì—ì„œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Langfuseë€?\n",
    "\n",
    "LangfuseëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ **ì˜¤í”ˆì†ŒìŠ¤ ê´€ì°°ì„±(observability) í”Œë«í¼**ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” ê¸°ëŠ¥\n",
    "- ğŸ“Š **Tracing**: LLM í˜¸ì¶œ ê³¼ì • ì¶”ì  ë° ì‹œê°í™”\n",
    "- ğŸ“ˆ **Analytics**: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë¹„ìš© ë¶„ì„\n",
    "- ğŸ¯ **Prompt Management**: í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬\n",
    "- ğŸ” **Debugging**: ì—ëŸ¬ ë° ì„±ëŠ¥ ì´ìŠˆ ë””ë²„ê¹…\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€?\n",
    "- LLM í˜¸ì¶œì„ ê°€ì‹œí™”\n",
    "- ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰, ë¹„ìš© ì¶”ì \n",
    "- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë¬¸ì œ ë””ë²„ê¹…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Dockerë¡œ ì…€í”„ í˜¸ìŠ¤íŒ…\n\n### ê°€ì¥ ì‰¬ìš´ ë°©ë²• (ì¶”ì²œ!)\n\n```bash\n# Langfuse ì €ì¥ì†Œ í´ë¡ \ngit clone https://github.com/langfuse/langfuse.git\ncd langfuse\n\n# Docker Compose ì‹¤í–‰ - ë!\ndocker compose up\n```\n\n### ì‹¤í–‰ í™•ì¸\n```bash\n# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰\ndocker compose up -d\n\n# ë¡œê·¸ í™•ì¸\ndocker compose logs -f\n\n# ì¤‘ì§€\ndocker compose down\n```\n\n### ì ‘ì†\n- URL: http://localhost:3000\n- ì²« ì ‘ì† ì‹œ íšŒì›ê°€ì… í›„ ì‚¬ìš©\n\n### API í‚¤ ë°œê¸‰\n1. ëŒ€ì‹œë³´ë“œ ë¡œê·¸ì¸\n2. Settings â†’ API Keys\n3. \"Create New Key\" í´ë¦­\n4. Public Keyì™€ Secret Key ë³µì‚¬í•˜ì—¬ .env íŒŒì¼ì— ì €ì¥\n\n```bash\n# .env íŒŒì¼ì— ì¶”ê°€\nLANGFUSE_PUBLIC_KEY=pk-lf-...\nLANGFUSE_SECRET_KEY=sk-lf-...\nLANGFUSE_HOST=http://localhost:3000\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python SDK ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langfuse langchain-openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Langfuse ì„¤ì •\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-...\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\", \"sk-lf-...\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"http://localhost:3000\")\n",
    "\n",
    "# OpenAI ì„¤ì •\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"âš ï¸ .env íŒŒì¼ì— API í‚¤ë“¤ì„ ì„¤ì •í•˜ì„¸ìš”\")\n",
    "else:\n",
    "    print(\"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ê¸°ë³¸ Trace Logging\n",
    "\n",
    "### ê°„ë‹¨í•œ ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Langfuse ì´ˆê¸°í™”\n",
    "langfuse = Langfuse(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "llm = ChatOpenAI()\n",
    "prompt = \"Pythonì˜ ì¥ì  3ê°€ì§€ëŠ”?\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Trace ìƒì„±\n",
    "trace = langfuse.trace(\n",
    "    name=\"simple-llm-call\",\n",
    "    user_id=\"user-123\"\n",
    ")\n",
    "\n",
    "# Generation ê¸°ë¡\n",
    "trace.generation(\n",
    "    name=\"openai-call\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    input=prompt,\n",
    "    output=response.content,\n",
    "    usage={\n",
    "        \"prompt_tokens\": 10,\n",
    "        \"completion_tokens\": 50,\n",
    "        \"total_tokens\": 60\n",
    "    }\n",
    ")\n",
    "\n",
    "# ë°ì´í„° ì „ì†¡\n",
    "langfuse.flush()\n",
    "\n",
    "print(\"âœ… Traceê°€ Langfuseì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”: {LANGFUSE_HOST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì¶”ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_query(user_query: str, user_id: str):\n",
    "    # ë©”ì¸ trace\n",
    "    trace = langfuse.trace(\n",
    "        name=\"user-query-pipeline\",\n",
    "        user_id=user_id,\n",
    "        input=user_query,\n",
    "        metadata={\"source\": \"notebook\"}\n",
    "    )\n",
    "    \n",
    "    # Step 1: ì…ë ¥ ê²€ì¦\n",
    "    validation_span = trace.span(\n",
    "        name=\"validate-input\",\n",
    "        input=user_query\n",
    "    )\n",
    "    time.sleep(0.1)\n",
    "    is_valid = len(user_query) > 0\n",
    "    validation_span.end(output={\"valid\": is_valid})\n",
    "    \n",
    "    # Step 2: LLM í˜¸ì¶œ\n",
    "    llm = ChatOpenAI()\n",
    "    response = llm.invoke(user_query)\n",
    "    \n",
    "    llm_generation = trace.generation(\n",
    "        name=\"generate-response\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        input=user_query,\n",
    "        output=response.content\n",
    "    )\n",
    "    \n",
    "    # Step 3: í›„ì²˜ë¦¬\n",
    "    postprocess_span = trace.span(\n",
    "        name=\"post-process\",\n",
    "        input=response.content\n",
    "    )\n",
    "    final_response = response.content.strip()\n",
    "    postprocess_span.end(output=final_response)\n",
    "    \n",
    "    # Trace ì¢…ë£Œ\n",
    "    trace.update(output=final_response)\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = process_query(\"ë°ì½”ë ˆì´í„°ë€?\", \"user-456\")\n",
    "langfuse.flush()\n",
    "\n",
    "print(f\"ê²°ê³¼: {result}\")\n",
    "print(f\"\\nëŒ€ì‹œë³´ë“œì—ì„œ trace í™•ì¸: {LANGFUSE_HOST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain í†µí•©\n",
    "\n",
    "LangChain ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Langfuse ì½œë°± í•¸ë“¤ëŸ¬\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# LangChain LLMì— ì½œë°± ì¶”ê°€\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    callbacks=[langfuse_handler]\n",
    ")\n",
    "\n",
    "# ì‚¬ìš© - ìë™ìœ¼ë¡œ ì¶”ì ë¨!\n",
    "response = llm.invoke(\"LangChainì´ë€?\")\n",
    "print(response.content)\n",
    "\n",
    "print(f\"\\nâœ… ìë™ìœ¼ë¡œ Langfuseì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainì—ì„œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\")\n",
    "llm = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ì‹¤í–‰ (configì— ì½œë°± ì „ë‹¬)\n",
    "result = chain.invoke(\n",
    "    {\"topic\": \"FastAPI\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "print(result)\n",
    "print(f\"\\nâœ… Chain ì‹¤í–‰ì´ Langfuseì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëŒ€í™”í˜• ì±—ë´‡ ì¶”ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# ì„¤ì •\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST,\n",
    "    user_id=\"user-789\",\n",
    "    session_id=\"session-001\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(callbacks=[langfuse_handler])\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ëŒ€í™” - ëª¨ë“  í„´ì´ ì¶”ì ë¨\n",
    "print(\"Bot:\", conversation.predict(input=\"ë‚´ ì´ë¦„ì€ ë¯¼ìˆ˜ì•¼\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"Pythonì„ ë°°ìš°ê³  ì‹¶ì–´\"))\n",
    "\n",
    "print(f\"\\nâœ… ì „ì²´ ëŒ€í™”ê°€ Langfuseì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"session-001ë¡œ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ëŒ€ì‹œë³´ë“œ í™œìš©\n",
    "\n",
    "ëŒ€ì‹œë³´ë“œ (http://localhost:3000)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´:\n",
    "\n",
    "### Traces í™”ë©´\n",
    "- ëª¨ë“  trace ëª©ë¡\n",
    "- í•„í„°ë§: ì‚¬ìš©ì, ë‚ ì§œ, ëª¨ë¸\n",
    "- ê²€ìƒ‰: ì…ë ¥/ì¶œë ¥ ë‚´ìš©\n",
    "\n",
    "### Trace ìƒì„¸ í™”ë©´\n",
    "```\n",
    "Trace: user-query-pipeline\n",
    "â”œâ”€â”€ Span: validate-input (100ms)\n",
    "â”œâ”€â”€ Generation: generate-response (500ms)\n",
    "â”‚   â”œâ”€â”€ Model: gpt-3.5-turbo\n",
    "â”‚   â”œâ”€â”€ Tokens: 60\n",
    "â”‚   â””â”€â”€ Cost: $0.0001\n",
    "â””â”€â”€ Span: post-process (50ms)\n",
    "\n",
    "Total: 650ms, $0.0001\n",
    "```\n",
    "\n",
    "### Analytics í™”ë©´\n",
    "- ì‹œê°„ë³„ ìš”ì²­ ìˆ˜\n",
    "- í‰ê·  ì‘ë‹µ ì‹œê°„\n",
    "- í† í° ì‚¬ìš©ëŸ‰\n",
    "- ë¹„ìš© ì¶”ì´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì‹¤ìŠµ ê³¼ì œ\n",
    "\n",
    "### Level 1\n",
    "1. Dockerë¡œ Langfuse ì…€í”„ í˜¸ìŠ¤íŒ… ì„¤ì •í•˜ê³  ì ‘ì†í•˜ê¸°\n",
    "2. ê°„ë‹¨í•œ LLM í˜¸ì¶œì„ traceë¡œ ê¸°ë¡í•˜ê³  ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸\n",
    "3. LangChain ì½œë°± í•¸ë“¤ëŸ¬ë¡œ ìë™ ì¶”ì  êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì œ 1: ê¸°ë³¸ trace ìƒì„±\n",
    "# TODO: ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2\n",
    "4. ì—¬ëŸ¬ spanì„ í¬í•¨í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì¶”ì í•˜ê¸°\n",
    "5. ì‚¬ìš©ìë³„ë¡œ ë‹¤ë¥¸ session_idë¥¼ ë¶€ì—¬í•˜ì—¬ ì„¸ì…˜ ê´€ë¦¬\n",
    "6. ì—ëŸ¬ ë°œìƒ ì‹œ trace.event()ë¡œ ê¸°ë¡í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì œ 2: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°\n",
    "# TODO: ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 3\n",
    "7. ConversationChain + Langfuseë¡œ ì „ì²´ ëŒ€í™” ì„¸ì…˜ ì¶”ì \n",
    "8. ëŒ€ì‹œë³´ë“œ Analyticsì—ì„œ ì„±ëŠ¥ ë³‘ëª© êµ¬ê°„ ì°¾ê¸°\n",
    "9. í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ë° A/B í…ŒìŠ¤íŠ¸ (ëŒ€ì‹œë³´ë“œ ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì œ 3: ì„¸ì…˜ ì¶”ì \n",
    "# TODO: ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ë¦¬\n",
    "\n",
    "Langfuseì˜ ì¥ì :\n",
    "- âœ… LLM í˜¸ì¶œ ê³¼ì •ì„ ì™„ì „íˆ ê°€ì‹œí™”\n",
    "- âœ… ì‘ë‹µ ì‹œê°„, í† í°, ë¹„ìš© ìë™ ì¶”ì \n",
    "- âœ… LangChainê³¼ ë„¤ì´í‹°ë¸Œ í†µí•©\n",
    "- âœ… í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë””ë²„ê¹… ìš©ì´\n",
    "- âœ… ì…€í”„ í˜¸ìŠ¤íŒ…ìœ¼ë¡œ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ë³´ì¥\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "LangChain + Langfuse í†µí•© ì˜ˆì‹œë¥¼ í™•ì¸í•˜ì„¸ìš”!\n",
    "\n",
    "ğŸ‘‰ [langchain_langfuse_example.py](langchain_langfuse_example.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}