{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Langfuse 기초 실습\n",
    "\n",
    "## 학습 목표\n",
    "- Docker로 Langfuse를 셀프 호스팅하기\n",
    "- Trace logging으로 LLM 호출 추적하기\n",
    "- LangChain과 통합하여 자동으로 로깅하기\n",
    "- 대시보드에서 성능 모니터링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Langfuse란?\n",
    "\n",
    "Langfuse는 LLM 애플리케이션을 위한 **오픈소스 관찰성(observability) 플랫폼**입니다.\n",
    "\n",
    "### 주요 기능\n",
    "- 📊 **Tracing**: LLM 호출 과정 추적 및 시각화\n",
    "- 📈 **Analytics**: 성능 메트릭 및 비용 분석\n",
    "- 🎯 **Prompt Management**: 프롬프트 버전 관리\n",
    "- 🔍 **Debugging**: 에러 및 성능 이슈 디버깅\n",
    "\n",
    "### 왜 필요한가?\n",
    "- LLM 호출을 가시화\n",
    "- 응답 시간, 토큰 사용량, 비용 추적\n",
    "- 프로덕션 환경에서 문제 디버깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Docker로 셀프 호스팅\n\n### 가장 쉬운 방법 (추천!)\n\n```bash\n# Langfuse 저장소 클론\ngit clone https://github.com/langfuse/langfuse.git\ncd langfuse\n\n# Docker Compose 실행 - 끝!\ndocker compose up\n```\n\n### 실행 확인\n```bash\n# 백그라운드 실행\ndocker compose up -d\n\n# 로그 확인\ndocker compose logs -f\n\n# 중지\ndocker compose down\n```\n\n### 접속\n- URL: http://localhost:3000\n- 첫 접속 시 회원가입 후 사용\n\n### API 키 발급\n1. 대시보드 로그인\n2. Settings → API Keys\n3. \"Create New Key\" 클릭\n4. Public Key와 Secret Key 복사하여 .env 파일에 저장\n\n```bash\n# .env 파일에 추가\nLANGFUSE_PUBLIC_KEY=pk-lf-...\nLANGFUSE_SECRET_KEY=sk-lf-...\nLANGFUSE_HOST=http://localhost:3000\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python SDK 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langfuse langchain-openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Langfuse 설정\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-...\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\", \"sk-lf-...\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"http://localhost:3000\")\n",
    "\n",
    "# OpenAI 설정\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ .env 파일에 API 키들을 설정하세요\")\n",
    "else:\n",
    "    print(\"✅ API 키 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 기본 Trace Logging\n",
    "\n",
    "### 간단한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Langfuse 초기화\n",
    "langfuse = Langfuse(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI()\n",
    "prompt = \"Python의 장점 3가지는?\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Trace 생성\n",
    "trace = langfuse.trace(\n",
    "    name=\"simple-llm-call\",\n",
    "    user_id=\"user-123\"\n",
    ")\n",
    "\n",
    "# Generation 기록\n",
    "trace.generation(\n",
    "    name=\"openai-call\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    input=prompt,\n",
    "    output=response.content,\n",
    "    usage={\n",
    "        \"prompt_tokens\": 10,\n",
    "        \"completion_tokens\": 50,\n",
    "        \"total_tokens\": 60\n",
    "    }\n",
    ")\n",
    "\n",
    "# 데이터 전송\n",
    "langfuse.flush()\n",
    "\n",
    "print(\"✅ Trace가 Langfuse에 기록되었습니다!\")\n",
    "print(f\"대시보드에서 확인하세요: {LANGFUSE_HOST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 복잡한 워크플로우 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_query(user_query: str, user_id: str):\n",
    "    # 메인 trace\n",
    "    trace = langfuse.trace(\n",
    "        name=\"user-query-pipeline\",\n",
    "        user_id=user_id,\n",
    "        input=user_query,\n",
    "        metadata={\"source\": \"notebook\"}\n",
    "    )\n",
    "    \n",
    "    # Step 1: 입력 검증\n",
    "    validation_span = trace.span(\n",
    "        name=\"validate-input\",\n",
    "        input=user_query\n",
    "    )\n",
    "    time.sleep(0.1)\n",
    "    is_valid = len(user_query) > 0\n",
    "    validation_span.end(output={\"valid\": is_valid})\n",
    "    \n",
    "    # Step 2: LLM 호출\n",
    "    llm = ChatOpenAI()\n",
    "    response = llm.invoke(user_query)\n",
    "    \n",
    "    llm_generation = trace.generation(\n",
    "        name=\"generate-response\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        input=user_query,\n",
    "        output=response.content\n",
    "    )\n",
    "    \n",
    "    # Step 3: 후처리\n",
    "    postprocess_span = trace.span(\n",
    "        name=\"post-process\",\n",
    "        input=response.content\n",
    "    )\n",
    "    final_response = response.content.strip()\n",
    "    postprocess_span.end(output=final_response)\n",
    "    \n",
    "    # Trace 종료\n",
    "    trace.update(output=final_response)\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# 실행\n",
    "result = process_query(\"데코레이터란?\", \"user-456\")\n",
    "langfuse.flush()\n",
    "\n",
    "print(f\"결과: {result}\")\n",
    "print(f\"\\n대시보드에서 trace 확인: {LANGFUSE_HOST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain 통합\n",
    "\n",
    "LangChain 콜백 핸들러를 사용하면 자동으로 추적됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Langfuse 콜백 핸들러\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# LangChain LLM에 콜백 추가\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    callbacks=[langfuse_handler]\n",
    ")\n",
    "\n",
    "# 사용 - 자동으로 추적됨!\n",
    "response = llm.invoke(\"LangChain이란?\")\n",
    "print(response.content)\n",
    "\n",
    "print(f\"\\n✅ 자동으로 Langfuse에 기록되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST\n",
    ")\n",
    "\n",
    "# 체인 구성\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대해 설명해줘\")\n",
    "llm = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 실행 (config에 콜백 전달)\n",
    "result = chain.invoke(\n",
    "    {\"topic\": \"FastAPI\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "print(result)\n",
    "print(f\"\\n✅ Chain 실행이 Langfuse에 기록되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대화형 챗봇 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# 설정\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key=LANGFUSE_SECRET_KEY,\n",
    "    host=LANGFUSE_HOST,\n",
    "    user_id=\"user-789\",\n",
    "    session_id=\"session-001\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(callbacks=[langfuse_handler])\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 대화 - 모든 턴이 추적됨\n",
    "print(\"Bot:\", conversation.predict(input=\"내 이름은 민수야\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"내 이름이 뭐였지?\"))\n",
    "print()\n",
    "print(\"Bot:\", conversation.predict(input=\"Python을 배우고 싶어\"))\n",
    "\n",
    "print(f\"\\n✅ 전체 대화가 Langfuse에 기록되었습니다!\")\n",
    "print(f\"session-001로 대시보드에서 확인하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 대시보드 활용\n",
    "\n",
    "대시보드 (http://localhost:3000)에서 확인할 수 있는 정보:\n",
    "\n",
    "### Traces 화면\n",
    "- 모든 trace 목록\n",
    "- 필터링: 사용자, 날짜, 모델\n",
    "- 검색: 입력/출력 내용\n",
    "\n",
    "### Trace 상세 화면\n",
    "```\n",
    "Trace: user-query-pipeline\n",
    "├── Span: validate-input (100ms)\n",
    "├── Generation: generate-response (500ms)\n",
    "│   ├── Model: gpt-3.5-turbo\n",
    "│   ├── Tokens: 60\n",
    "│   └── Cost: $0.0001\n",
    "└── Span: post-process (50ms)\n",
    "\n",
    "Total: 650ms, $0.0001\n",
    "```\n",
    "\n",
    "### Analytics 화면\n",
    "- 시간별 요청 수\n",
    "- 평균 응답 시간\n",
    "- 토큰 사용량\n",
    "- 비용 추이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 실습 과제\n",
    "\n",
    "### Level 1\n",
    "1. Docker로 Langfuse 셀프 호스팅 설정하고 접속하기\n",
    "2. 간단한 LLM 호출을 trace로 기록하고 대시보드에서 확인\n",
    "3. LangChain 콜백 핸들러로 자동 추적 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 1: 기본 trace 생성\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2\n",
    "4. 여러 span을 포함한 복잡한 워크플로우 추적하기\n",
    "5. 사용자별로 다른 session_id를 부여하여 세션 관리\n",
    "6. 에러 발생 시 trace.event()로 기록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 2: 복잡한 워크플로우\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 3\n",
    "7. ConversationChain + Langfuse로 전체 대화 세션 추적\n",
    "8. 대시보드 Analytics에서 성능 병목 구간 찾기\n",
    "9. 프롬프트 버전 관리 및 A/B 테스트 (대시보드 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제 3: 세션 추적\n",
    "# TODO: 코드 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "Langfuse의 장점:\n",
    "- ✅ LLM 호출 과정을 완전히 가시화\n",
    "- ✅ 응답 시간, 토큰, 비용 자동 추적\n",
    "- ✅ LangChain과 네이티브 통합\n",
    "- ✅ 프로덕션 환경에서 디버깅 용이\n",
    "- ✅ 셀프 호스팅으로 데이터 프라이버시 보장\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "LangChain + Langfuse 통합 예시를 확인하세요!\n",
    "\n",
    "👉 [langchain_langfuse_example.py](langchain_langfuse_example.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}